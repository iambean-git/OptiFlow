{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preamble import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import re\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 데이터 로딩 및 전처리 (기존 함수 재사용)\n",
    "def load_and_preprocess(data_path):\n",
    "  df = pd.read_csv(data_path)\n",
    "\n",
    "  def parse_data_array(data_str):\n",
    "    data_str = re.sub(r'\\s+', ' ', data_str).strip()\n",
    "    if data_str == '[]':\n",
    "      return None\n",
    "    try:\n",
    "      return np.fromstring(data_str[1:-1], sep=' ')\n",
    "    except ValueError:\n",
    "      print(f\"Warning: Could not parse data array: {data_str}\")\n",
    "      return None\n",
    "\n",
    "  df['data_array'] = df['data_array'].apply(parse_data_array)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2 특징 추출 함수 (기존 함수 재사용)\n",
    "def extract_features(data_array):\n",
    "  x = np.array(data_array)\n",
    "  x = x[:len(x)//2]\n",
    "\n",
    "  features = []\n",
    "  features.append(np.max(x) - np.min(x))\n",
    "  features.append(np.mean(x))\n",
    "  if len(x) > 1:\n",
    "    features.append(np.std(x, ddof=1))\n",
    "  else:\n",
    "    features.append(0)\n",
    "  features.append(np.sqrt(np.mean(x**2)))\n",
    "  if len(x) > 1 and features[3] != 0:\n",
    "    features.append(np.max(np.abs(x)) / features[3])\n",
    "  else:\n",
    "    features.append(0)\n",
    "\n",
    "  if len(x) > 1 and features[2] != 0:\n",
    "    features.append(np.mean(((x - features[1]) / features[2])**3))\n",
    "    features.append(np.mean(((x - features[1]) / features[2])**4))\n",
    "  else:\n",
    "    features.append(0)\n",
    "    features.append(0)\n",
    "  return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.3 데이터프레임에 특징 추가 (기존 함수에서 약간 수정)\n",
    "def create_feature_df(df):\n",
    "  feature_list = []\n",
    "  for _, row in df.iterrows():\n",
    "    if row['data_array'] is None:\n",
    "      feature_list.append(None)\n",
    "    else:\n",
    "      features = extract_features(row['data_array'])\n",
    "      feature_list.append(features)\n",
    "\n",
    "  valid_features = [f for f in feature_list if f is not None]\n",
    "  if valid_features:\n",
    "    feature_df = pd.DataFrame(valid_features, columns=[f'feature_{i}' for i in range(7)])\n",
    "  else:\n",
    "    feature_df = pd.DataFrame()\n",
    "\n",
    "  feature_df = feature_df.reset_index(drop=True)\n",
    "\n",
    "  # 채널별 특징 결합 부분 (수정)\n",
    "  channel_features = []\n",
    "  for channel in df['channel_id'].unique():\n",
    "    channel_rows = df['channel_id'] == channel  # 조건에 맞는 행 필터링\n",
    "    \n",
    "    # 해당 채널의 데이터가 있고, data_array가 None이 아닌 경우만 처리\n",
    "    if channel_rows.any() and df.loc[channel_rows, 'data_array'].notna().any():\n",
    "      channel_df = feature_df.loc[channel_rows & df['data_array'].notna()].copy()\n",
    "      channel_df.columns = [f\"{col}_{channel}\" for col in channel_df.columns]\n",
    "      channel_features.append(channel_df)\n",
    "    else:\n",
    "      channel_features.append(pd.DataFrame()) # 빈 DataFrame 추가\n",
    "\n",
    "  if channel_features:\n",
    "    feature_df = pd.concat(channel_features, axis=1)\n",
    "  else:\n",
    "    feature_df = pd.DataFrame()\n",
    "  \n",
    "  # final_df 생성 (수정: 인덱스 리셋 시점 변경, 조건 추가)\n",
    "  final_df = pd.DataFrame()\n",
    "  if not feature_df.empty:\n",
    "    final_df = pd.concat([df.reset_index(drop=True), feature_df], axis=1)\n",
    "  else:\n",
    "    final_df = df.copy()  # feature_df가 비어있으면 원본 df 사용\n",
    "    print(\"Warning: No features extracted. Using original dataframe.\")\n",
    "  \n",
    "  return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 정상 범위 설정 및 레이블링 (새로운 함수)\n",
    "def set_normal_range_and_label(final_df, date_threshold='7D', threshold_std_warn=2, threshold_std_danger=4):\n",
    "  \"\"\"\n",
    "  각 모터별 초기 데이터를 기반으로 정상 범위를 설정하고, 이후 데이터를 레이블링합니다.\n",
    "\n",
    "  Args:\n",
    "      final_df: 특징 데이터프레임.\n",
    "      date_threshold: 정상 데이터로 간주할 기간 (예: '7D' - 7일).\n",
    "      threshold_std_warn: '주의' 레벨의 표준편차 임계값.\n",
    "      threshold_std_danger: '위험' 레벨의 표준편차 임계값.\n",
    "\n",
    "  Returns:\n",
    "      'failure_level' 열이 추가된 데이터프레임. (0: 정상, 1: 주의, 2: 위험, 3: 고장)\n",
    "  \"\"\"\n",
    "\n",
    "  final_df['failure_level'] = 0  # 초기값은 정상(0)\n",
    "  final_df['acq_date'] = pd.to_datetime(final_df['acq_date'])  # 날짜 타입 변환\n",
    "\n",
    "  for motor_id in final_df['motor_id'].unique():\n",
    "    motor_data = final_df[final_df['motor_id'] == motor_id].sort_values(by='acq_date')\n",
    "    \n",
    "    if motor_data.empty:\n",
    "      print(f\"Skipping motor {motor_id} due to empty data set.\")\n",
    "      continue\n",
    "\n",
    "    # 정상 데이터 기간 설정 (처음부터 date_threshold까지)\n",
    "    cutoff_date = motor_data['acq_date'].min() + pd.to_timedelta(date_threshold)\n",
    "    normal_data = motor_data[motor_data['acq_date'] <= cutoff_date]\n",
    "    \n",
    "    # 채널별 정상 범위 계산 (data_array가 None이 아닌 행만 사용)\n",
    "    for channel in motor_data['channel_id'].unique():\n",
    "      channel_normal_data = normal_data[(normal_data['channel_id'] == channel) & (normal_data['data_array'].notna())]\n",
    "      channel_features = channel_normal_data.filter(like=f'feature_') # 'feature_'로 시작하는 열만\n",
    "\n",
    "      if channel_features.empty:\n",
    "        print(f\"Skipping channel {channel} in motor {motor_id} due to empty normal data.\")\n",
    "        continue\n",
    "\n",
    "      # 결측치 처리 (SimpleImputer)\n",
    "      imputer = SimpleImputer(strategy='mean')\n",
    "      channel_features_imputed = imputer.fit_transform(channel_features)\n",
    "\n",
    "      # 정상 데이터의 평균과 표준편차 계산\n",
    "      normal_mean = np.mean(channel_features_imputed, axis=0)\n",
    "      normal_std = np.std(channel_features_imputed, axis=0)\n",
    "\n",
    "\n",
    "      # 이후 데이터 레이블링\n",
    "      channel_data = motor_data[(motor_data['channel_id'] == channel) & (motor_data['acq_date'] > cutoff_date)]\n",
    "\n",
    "      for index, row in channel_data.iterrows():\n",
    "        # data_array가 None이면 레이블링 건너뛰기\n",
    "        if row['data_array'] is None:\n",
    "          continue\n",
    "\n",
    "        current_features = row.filter(like=f'feature_').values.astype(float)  # 현재 행의 특징 값, float으로 타입 변환\n",
    "        if np.any(np.isnan(current_features)): # 결측치 확인\n",
    "          current_features = imputer.transform([current_features])[0] # 변환\n",
    "\n",
    "        # 벗어난 정도 계산 (Z-score 유사)\n",
    "        z_scores = (current_features - normal_mean) / normal_std\n",
    "        max_deviation = np.max(np.abs(z_scores))  # 가장 크게 벗어난 정도\n",
    "\n",
    "\n",
    "        if max_deviation > threshold_std_danger * normal_std.mean():  # 고장\n",
    "          final_df.loc[index, 'failure_level'] = 3\n",
    "        elif max_deviation > threshold_std_warn * normal_std.mean():  # 위험\n",
    "          final_df.loc[index, 'failure_level'] = 2\n",
    "        elif max_deviation > threshold_std_warn:   # 주의\n",
    "          final_df.loc[index, 'failure_level'] = 1\n",
    "\n",
    "  return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_8028\\178843254.py:10: DeprecationWarning: string or file could not be read to its end due to unmatched data; this will raise a ValueError in the future.\n",
      "  return np.fromstring(data_str[1:-1], sep=' ')\n"
     ]
    }
   ],
   "source": [
    "data_path = './data/pms_data_decompressed.csv'  # 실제 데이터 경로\n",
    "df = load_and_preprocess(data_path)\n",
    "final_df = create_feature_df(df)\n",
    "\n",
    "if final_df.empty:\n",
    "  print(\"No data available after feature extraction.\")\n",
    "else:\n",
    "  final_df = set_normal_range_and_label(final_df) # 새 레이블링 함수 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 데이터 분할 (시간순, 층화추출, failure_level 사용)\n",
    "final_df = final_df.sort_values(by='acq_date')\n",
    "X = final_df.drop(['motor_id', 'equipment_id', 'center_id', 'channel_id', 'acq_date', 'data_array', 'failure_level'], axis=1)\n",
    "y = final_df['failure_level']  # 다중 클래스 레이블\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. XGBoost 모델 학습 및 튜닝\n",
    "param_grid = {\n",
    "  'n_estimators': [100, 200, 300],\n",
    "  'max_depth': [3, 4, 5],\n",
    "  'learning_rate': [0.01, 0.1, 0.2],\n",
    "  'subsample': [0.8, 1.0],\n",
    "  'colsample_bytree': [0.8, 1.0],\n",
    "  'gamma': [0, 0.1, 0.2],\n",
    "  'reg_alpha': [0, 0.01, 0.1],\n",
    "  'reg_lambda': [0, 0.01, 0.1]\n",
    "}\n",
    "# 다중 클래스 분류를 위한 설정 변경\n",
    "xgb_model = xgb.XGBClassifier(objective='multi:softmax', num_class=4, eval_metric='mlogloss', use_label_encoder=False, random_state=42)\n",
    "grid_search = GridSearchCV(xgb_model, param_grid, cv=5, scoring='accuracy', verbose=3, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = './model/motor_xgboost_model_v2.json'\n",
    "best_model.save_model(model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 모델 평가\n",
    "y_pred = best_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 변수 중요도\n",
    "feature_importance = best_model.feature_importances_\n",
    "importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importance})\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "print(importance_df)\n",
    "return best_model, accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_book",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
